{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.conda/envs/social/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards:   0%|          | 0/21 [00:00<?, ?it/s]/root/.conda/envs/social/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Loading checkpoint shards: 100%|██████████| 21/21 [00:51<00:00,  2.44s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name = '/root/share/model_repos/internlm2-chat-20b'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "# Set `torch_dtype=torch.float16` to load model in float16, otherwise it will be loaded as float32 and cause OOM Error.\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, trust_remote_code=True).cuda()\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: 为了回答这个问题，我将使用谷歌搜索API来查找特朗普的出生日期。\n",
      "Action: google_search\n",
      "Action Input: {\"search_query\": \"特朗普 出生日期\"} \n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "google_search: Call this tool to interact with the 谷歌搜索 API. What is the 谷歌搜索 API useful for? 谷歌搜索是一个通用搜索引擎，可用于访问互联网、查询百科知识、了解时事新闻等。 Parameters: [{'name': 'search_query', 'description': '搜索关键词或短语', 'required': True, 'schema': {'type': 'string'}}] Format the arguments as a JSON object.\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [google_search]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can be repeated zero or more times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: 特朗普哪一年出生的？\n",
    "\"\"\"\n",
    "\n",
    "response, history = model.chat(tokenizer, prompt, history=[], temperature=0.1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('google_search', \"{'search_query': '你好'}\")\n"
     ]
    }
   ],
   "source": [
    "tet = '''第一次： Thought: 你好，请问有什么我可以帮助你的吗？\n",
    "Action: google_search\n",
    "Action Input: {'search_query': '你好'}'''\n",
    "\n",
    "def parse_latest_plugin_call(text):\n",
    "    plugin_name, plugin_args = '', ''\n",
    "    i = text.rfind('\\nAction:')\n",
    "    j = text.rfind('\\nAction Input:')\n",
    "    k = text.rfind('\\nObservation:')\n",
    "    if 0 <= i < j:  # If the text has `Action` and `Action input`,\n",
    "        if k < j:  # but does not contain `Observation`,\n",
    "            # then it is likely that `Observation` is ommited by the LLM,\n",
    "            # because the output text may have discarded the stop word.\n",
    "            text = text.rstrip() + '\\nObservation:'  # Add it back.\n",
    "        k = text.rfind('\\nObservation:')\n",
    "        plugin_name = text[i + len('\\nAction:') : j].strip()\n",
    "        plugin_args = text[j + len('\\nAction Input:') : k].strip()\n",
    "        text = text[:k]\n",
    "    return plugin_name, plugin_args\n",
    "\n",
    "print(parse_latest_plugin_call(tet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'search_query': '你好'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json5.loads(parse_latest_plugin_call(tet)[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen-moe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
